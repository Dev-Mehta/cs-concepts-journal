# MFU Cache

MFU cache is a variation of the LRU cache. The difference is that instead of deleting the least recently used entry, the MFU cache deletes the least frequently used entry.

Typically, MFU cache is used as the primary, backed by a secondary cache that uses an LRU replacement algorithm(an MRU cache). The idea is that the most recently used things will remain in the primary cache doing very quick access. This reduces the "churn" that you see in an MRU cache when a small number of items are used very frequently. It also prevents the commonly used items from being evicted from the cache just because they haven't been used for a while. 

MFU works well if you have a small number of items that are referenced very frequently, and a large number of items that are referenced infrequently. A typical desktop user, for example, might have three or four programs that he uses many times a day, hundreds of programs that he uses very infrequently. If you wanted to improve his experience by caching in memory programs so that they will start quickly, you are better off catching those things that he uses very frequently.

On the other hand, if you have a large number of items that are referenced essentially randomly, or some items are accessed slightly more often than, or items are typically referenced in batches(i.e. item A is accessed many times over a short period, and then not at all), then an LRU cache eviction scheme will likely be better.

#### Why do we use Most Recently Used(MRU) algorithm as evict policy?

Imagine you were looking up the details of buses as they arrived at bus stop, based on their bus number(or whatever identifier you find amusing). It's somewhat resonable to think that if you've just seen a number 36 bus, you're less likely to see another one imminently than to see one of the other buses that stops there.

Just one example, but  the idea is more general: In some cases, having "just seen something" is a good indicator that you're unlikely to see the same thing again soon.