# LFU Cache

Least Frequently Used is a type of cache algorithm used to manage memory within a computer. The standard characteristics of this method involves the system keeping track of the number of times of block is referenced in memory. When the cache is full and requires more room the system will purge the item with the lowest reference frequency.

LFU is sometimes combined with a least recently used algorithm and called LRFU.

The simplest method to employ an LFU algorithm is to assign a counter to every block that is loaded into the cache. Each time a reference is made to that block the counter is increased by one. When the cache reaches capacity and has a new block waiting to be inserted the system will search for the block with the lowest counter and remove it from the cache.

- Ideal LFU: there is a counter for each item in the catalogue
- Practical LFU: there is a counter for items stored in cache. The counter is forgotten if the item is evicted.

## Problems

While the LFU method may seem like an intuitive approach to memory management it is not without faults. Consider an item in memory which is reference repeatedly for a short period of time and is not accessed again for an extended period of time. Due to how rapidly it was accessed it's counter has increased drastically even though it will not be used again for a decent amount of time. This leaves other blocks which may actually be used more frequently susceptible to purging simply because they were accessed through a different method.

Moreover, new items that just entered the cache are subject to being removed very soon again, because they start with a low counter, even though they might be used very frequently after that. Due to major issues like these, an explicit LFU system is fairly uncommon; instead, there are hybrids that utilize LFU concepts.

## Implementation

```cpp
class LFUCache {
    private:
        unordered_map<int, int> key_val;
        unordered_map<int, int> key_use;
        unordered_map<int, deque<int>> uses;
        int min_uses;
        int capacity;

		// Remove stale values from the uses[min_uses] deque

        void refreshCache() {
            while (!uses[min_uses].empty()) {
                int tmp_key = uses[min_uses].front();
                // Found a non-stale value, so refreshing done
                if (key_use[tmp_key] == min_uses) break;
                // This is a stale value - remove it from the deque
                uses[min_uses].pop_front();
                // uses[min_uses] was populated only by stale values, so remove it
                if (uses[min_uses].empty()) {
                    uses.erase(min_uses);
                    // Find the next candidate min_uses
                    while (!uses.count(min_uses)) ++min_uses;
                }
            }
        }
        
    public:
        LFUCache(int capacity): min_uses(INT_MAX), capacity(capacity) {}
        int get(int key) {
            // Key doesn't exist in cache
            if (!key_val.count(key)) return -1;
            ++key_use[key];
            uses[key_use[key]].push_back(key);
            return key_val[key];
        }

        void put(int key, int value) {
            if (capacity == 0) return;
            // Prune the cache if at capacity and inserting a new value
            if (key_val.size() == capacity && !key_val.count(key)) {
                refreshCache();
                // Finished removing all stale values from the cache
                // We now know this value must be valid. Erase the value
                // With the minimum number of uses that was used last
                int to_remove = uses[min_uses].front();
                uses[min_uses].pop_front();
                key_val.erase(to_remove);
                key_use.erase(to_remove);
            }
            ++key_use[key];
            uses[key_use[key]].push_back(key);
            // If the number of uses of this newly insert key is a new minimum, update
            min_uses = min(min_uses, key_use[key]);
            key_val[key] = value;
        }
};
```